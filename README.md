Πατηστε το code για να φανει σωστα το κειμενο. Ενω επισης δεν δουλεψα στο google colab αλλα αντρεγραψα τον κωδικα και δουλεψα στο pycharm
1.
Οι αλλαγες που εκανα ηταν να κανονικοποιησω τα δεδομενα, να αλλαξω το learning rate τις epochs καθως και την αρχιτεκτονικη του νευρωνικου δυκτιου και τον αριθμο και το activation των νευρωνων των νευρωνων.
learning rate|epochs|activation|αρχιτεκτονικη και αριθμος νευρωνων.
0.004|25|'relu'|784,512,256,128,10: accuracy: 0.9851 - loss: 0.0565 - val_accuracy: 0.9765 - val_loss: 0.0803
0.005|25|'tanh'|784,512,256,128,10: accuracy: 0.9757 - loss: 0.0892 - val_accuracy: 0.9692 - val_loss: 0.1025
0.005|20|'relu'|784,512,256,128,10: accuracy: 0.9843 - loss: 0.0583 - val_accuracy: 0.9763 - val_loss: 0.0805
0.01|10|'relu'|784,512,256,128,10: accuracy: 0.9818 - loss: 0.0666 - val_accuracy: 0.9755 - val_loss: 0.0820
0.005|25|'relu'|784,512,256,128,64,10: accuracy: 0.9678 - loss: 0.1151 - val_accuracy: 0.9655 - val_loss: 0.1187
0.005|20|'relu'|784,512,256,128,64,10: accuracy: 0.9901 - loss: 0.0391 - val_accuracy: 0.9771 - val_loss: 0.0728
0.005|25|'relu'|784,512,256,128,10: accuracy: 0.9889 - loss: 0.0429 - val_accuracy: 0.9781 - val_loss: 0.0742

Oποτε η τελικη μου επιλογη ειναι: 0.005|25|'relu'|784,512,256,128,10

2.
Αυξησα τις εποχες σε 30.
0.005|30|'relu'|784,512,256,128,10: accuracy: 0.9928 - loss: 0.0317 - val_accuracy: 0.9791 - val_loss: 0.0711

3.
a. Θεωρω πως ειναι καλο, παρολα αυτα υπαρχει χωρος βελτιωσης καθως παρατηρησα οτι υπαρχουν πολυ αριθμοι που διακρινονται με δυσκολια απο τον ιδιο τον ανθρωπο.
b. Οχι δεν ειναι ολα το ιδιο σημαντικα. Τα κεντρικα ειναι πιο σημαντικα καθως τα περισσοτερα ψηφια οταν τα σχεδιαζουμε περνανε απο το κεντρο ενω οι ακρες χρησιμοποιουνται πολυ σπανια εως καθολου.
c. Οταν εχουμε εναν πολυ μεγαλο αριθμο δεδομενων και ενα πολυπλοκο προτυπο που δυσκολα μοντελοποιειται το προβλημα.
d. Θεωρω πως ναι μπορει να χρησιμοποιηθει σε ολους του κλαδους αφου ειναι πολυ ευελικτη και εχει μεγαλη ισχυ.
